
# [2025 데이스쿨 ML2] 자동차 보험사기 탐지 AI 해커톤 참가기

> 2025년 데이스쿨 ML2(기초) 트랙에서 진행한 '자동차 보험사기 탐지 해커톤' 프로젝트의 접근 방식과 배운 점을 기록합니다.

## 1. 도입: 풀려는 문제 (The Problem)

이번 해커톤의 주제는 '자동차 보험사기 탐지(Fraud Detection)'였습니다.

자동차 보험사기는 매년 막대한 사회적 비용을 발생시키며, 결국 선량한 가입자들의 보험료 인상으로 이어집니다. 따라서 AI 기술을 활용해 보험 청구 데이터 속에서 사기 패턴을 신속하게 식별해내는 것은 매우 중요한 과제입니다.

저희의 목표는 주어진 데이터를 분석하여, **어떤 청구가 '사기'인지를 효과적으로 예측하는 머신러닝 모델**을 개발하는 것이었습니다.

## 2. 가장 큰 난관: 현실의 데이터는 불균형하다

프로젝트를 시작하며 마주한 가장 큰 기술적 허들은 **'극심한 데이터 불균형(Imbalanced Data)'**이었습니다.

전체 청구 데이터 중 '사기(Fraud)'로 레이블링된 데이터는 1% 남짓에 불과했습니다.

이는 모델 학습에 심각한 문제를 일으킵니다. 만약 모델이 모든 데이터를 '정상'이라고만 예측해도, 99%의 정확도(Accuracy)를 달성할 수 있기 때문입니다. 이는 **'정확도의 함정(Accuracy Paradox)'** 이라 불리며, 우리가 풀려는 실제 문제(사기 탐지)는 전혀 해결하지 못하는 상황을 만듭니다.

## 3. 우리의 접근 방식 (Our Approach)

이 문제를 해결하기 위해, 우리는 다음 세 가지 단계에 집중했습니다.

### (1) 평가지표(Metric)의 재정의: "무엇을 잡을 것인가?"

'정확도(Accuracy)'가 무의미하다는 것을 인지하고, 비즈니스 목적에 맞는 새로운 평가지표를 설정했습니다.

* **Precision (정밀도)**: 모델이 "사기"라고 예측한 것 중, *실제 사기*인 비율.
    * (중요성: 정상을 사기로 잘못 판단하면 안 됨 - 고객 민원, 조사 비용 발생)
* **Recall (재현율)**: *실제 사기* 중에서, 모델이 "사기"라고 맞춘 비율.
    * (중요성: 실제 사기를 놓치면 안 됨 - 기업 손실 발생)

두 지표는 트레이드오프(Trade-off) 관계에 있습니다. 우리는 둘 다 중요하다고 판단하여, 이들의 조화 평균인 **F1-Score**를 핵심 평가지표로 삼았습니다. 또한, 모델의 전반적인 판별 성능을 확인하기 위해 **AUC-ROC** 값을 보조 지표로 활용했습니다.

### (2) 피처 엔지니어링: "모델은 데이터가 아는 만큼만 본다"

"Garbage In, Garbage Out."
다양한 모델을 튜닝하는 것보다, 모델이 더 잘 학습할 수 있도록 '양질의 데이터'를 만들어주는 **피처 엔지니어링(Feature Engineering)**에 가장 많은 시간을 쏟았습니다.

단순히 주어진 변수(Column)를 그대로 사용하는 대신, 도메인 지식을 상상하며 다음과 같은 파생 변수들을 생성했습니다.

* (예시) `사고시간_대비_신고시간_차이`
* (예시) `운전경력_대비_총사고횟수`
* (예시) `특정_사고유형_빈도`
* (예시) `차량연식_대비_수리비용`

이 과정에서 어떤 피처가 모델 성능에 긍정적인 영향을 주는지(Feature Importance) 지속적으로 확인하며 데이터를 정제했습니다.

### (3) 불균형 데이터 처리 및 모델링

피처 엔지니어링이 완료된 데이터를 바탕으로 불균형 문제를 직접 처리했습니다.

1.  **샘플링 (Sampling)**: 소수 클래스인 '사기' 데이터를 인위적으로 증식시키는 오버샘플링(Oversampling) 기법 중 **SMOTE(Synthetic Minority Over-sampling Technique)**를 적용하여 데이터셋의 균형을 맞추려 시도했습니다.

2.  **모델 가중치 부여 (Class Weighting)**: 샘플링 대신, 모델이 학습할 때 '사기' 클래스(소수 클래스)의 오류에 더 큰 페널티(가중치)를 부여하는 방식을 사용했습니다.

최종적으로는 불균형 데이터 처리에 강점을 보이며 해석이 용이한 트리 기반의 앙상블 모델, **XGBoost**와 **LightGBM**을 주력으로 사용했습니다. 특히 LightGBM의 `is_unbalance=True` 파라미터나 XGBoost의 `scale_pos_weight` 파라미터 튜닝을 통해 불균형 문제를 효과적으로 제어하려 노력했습니다.

## 4. 결과 및 회고 (Lessons Learned)

이번 해커톤을 통해 단순히 모델을 학습시키는 것을 넘어, 현실의 비즈니스 문제를 AI로 해결하는 과정을 깊이 있게 경험할 수 있었습니다.

1.  **도메인 지식의 중요성**: 보험사기가 어떻게 일어나는지 이해하려 노력하는 것이, 유의미한 피처(Feature)를 만드는 데 결정적인 역할을 했습니다.
2.  **데이터 중심적 접근**: 최고의 모델을 찾는 것보다, 모델이 잘 학습할 수 있도록 데이터를 정제하고 가공하는 '피처 엔지니어링'과 '데이터 전처리'가 성능에 훨씬 더 큰 영향을 미친다는 것을 체감했습니다.
3.  **올바른 평가지표의 힘**: 풀려는 문제에 맞는 평가지표(F1-Score, AUC)를 설정하는 것이 프로젝트의 방향성을 잃지 않게 만드는 나침반이 되어주었습니다.

아직 부족한 점이 많지만, '왜 이 기술을 사용하는가?'라는 질문을 끊임없이 되뇌며 성장하는 개발자가 되어야겠다고 다짐하는 계기가 되었습니다.
